{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5575fad4",
   "metadata": {},
   "source": [
    "# 源数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286db6b0",
   "metadata": {},
   "source": [
    "## 1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e4ad43",
   "metadata": {},
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "77a540d7",
   "metadata": {},
   "source": [
    "## 2 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d6fc0b",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "data_train=r'C:\\Users\\30535\\Desktop\\train.csv'\n",
    "data_test=r'C:\\Users\\30535\\Desktop\\test.csv'\n",
    "ds=load_dataset('csv',data_files={'train':data_train, 'test': data_test},\n",
    "                                split=['train', 'test'])\n",
    "ds"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d63ae622",
   "metadata": {},
   "source": [
    "## 4 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d71b691",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model_path=r'H:\\models\\bloom-6b4-zh'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f48676e",
   "metadata": {},
   "source": [
    "def process_func(examples):\n",
    "    MAX_LENGTH = 150\n",
    "    contents='机器翻译:\\n' + examples['src']\n",
    "    # 对输入与label进行编码\n",
    "    inputs=tokenizer(contents)\n",
    "    labels = tokenizer(text_target=examples['tgt'] + tokenizer.eos_token)\n",
    "    input_ids=inputs[\"input_ids\"]+labels[\"input_ids\"]\n",
    "    attention_mask=inputs[\"attention_mask\"] + labels[\"attention_mask\"]\n",
    "    labels = [-100] * len(inputs[\"input_ids\"]) + labels[\"input_ids\"]\n",
    "    # 数据截断\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8f1a88",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tokenized_train=ds[0].map(process_func, remove_columns=ds[0].column_names)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ad20e4d9",
   "metadata": {},
   "source": [
    "## 5 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f5fa333",
   "metadata": {},
   "source": [
    "import torch\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,low_cpu_mem_usage=True,torch_dtype=torch.half,\n",
    "                                            load_in_4bit=True, # 4bit混合训练\n",
    "                                            bnb_4bit_compute_dtype=torch.half,\n",
    "                                             bnb_4bit_quant_type='nf4', # nf4 量化\n",
    "                                             bnb_4bit_use_double_quant=True\n",
    "                                            )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320650bf",
   "metadata": {},
   "source": [
    "model.enable_input_require_grads() # 执行这行代码，在使用gradient_checkpointing时才不会报错"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3aaa4c6",
   "metadata": {},
   "source": [
    "# 6.1 创建配置文件\n",
    "from peft import LoraConfig,get_peft_model,TaskType\n",
    "comfig = LoraConfig(task_type=TaskType.CAUSAL_LM)\n",
    "comfig"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc4ec1c",
   "metadata": {},
   "source": [
    "# 6.2 创建模型\n",
    "model_lora = get_peft_model(model,comfig)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4495dfdb",
   "metadata": {},
   "source": [
    "model_lora=model_lora.half()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33be677b",
   "metadata": {},
   "source": [
    "model_lora.print_trainable_parameters()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43d387bd",
   "metadata": {},
   "source": [
    "model.device"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f7d689a5",
   "metadata": {},
   "source": [
    "## 7 配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77a2e300",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\" # 防止日志输出到wandb.ai\n",
    "args= TrainingArguments(\n",
    "                                  output_dir='./modelcheak/m5',\n",
    "                                  logging_dir=r'./modelcheak/m5',\n",
    "                                  per_device_train_batch_size=16,  # batch_size\n",
    "                                  gradient_accumulation_steps=2,\n",
    "                                  logging_steps=20,\n",
    "                                  optim=\"paged_adamw_32bit\",  # 分页优化器，QLora要使用\n",
    "                                  num_train_epochs=1,\n",
    "                                  gradient_checkpointing=True\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "122adaa1",
   "metadata": {},
   "source": [
    "## 8 创建训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b7e698",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "trainr=Trainer(\n",
    "    args=args,\n",
    "    model=model_lora,\n",
    "    train_dataset=tokenized_train,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0943fb9e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "trainr.train()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7ae220ef",
   "metadata": {},
   "source": [
    "## 9 权重合并与"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e8cbedf",
   "metadata": {},
   "source": [
    "model.device"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5aca0d3b",
   "metadata": {},
   "source": [
    "from peft import PeftModel\n",
    "# model_id 是checkpoint那个路径\n",
    "prft_model=PeftModel.from_pretrained(model=model,model_id=r\"C:\\Users\\30535\\Desktop\\CodeProgram\\Python\\deepstudy\\code2\\使用Transformer进行中英文翻译\\modelcheak\\m5\\checkpoint-2500\")\n",
    "# 权重合并\n",
    "prft_model=prft_model.to('cuda')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc687a",
   "metadata": {},
   "source": [
    "# 模型保存\n",
    "# merge_model.save_pretrained('./modelcheak/trans11')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce272f6e",
   "metadata": {},
   "source": [
    "import re\n",
    "import sacrebleu\n",
    "def is_english_sentence(sentence):\n",
    "    # 使用正则表达式检查句子中是否包含英文字母\n",
    "    english_pattern = re.compile(r'[a-zA-Z]')\n",
    "    match = english_pattern.search(sentence)\n",
    "    \n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "smooth = SmoothingFunction().method1\n",
    "bleu_scores=[]\n",
    "m1,m2=[],[]\n",
    "m3,m4=[],[]\n",
    "import time\n",
    "t=time.time()\n",
    "for i in range(len(ds[1]['src'])):\n",
    "    if i%40==0:\n",
    "        print(i/len(ds[1]['src']))\n",
    "    x=\"机器翻译:\\n{}\".format(ds[1]['src'][i]).strip()\n",
    "    ipt = tokenizer(x,return_tensors='pt').to('cuda')\n",
    "#     print('被翻译句子： ',ds[1]['src'][i])\n",
    "    y=tokenizer.decode(prft_model.generate(**ipt,max_length=150, do_sample=False)[0],skip_special_tokens=True)[len(x):]\n",
    "#     print('翻译结果: ',y)\n",
    "#     print()\n",
    "    if is_english_sentence(ds[1]['tgt'][i]):\n",
    "        m1.append(ds[1]['tgt'][i])\n",
    "        m2.append([y])\n",
    "    else:\n",
    "        m3.append(list(ds[1]['tgt'][i][:-1]))\n",
    "        m4.append([list(y)[:-1]])\n",
    "# print('时间',time.time()-t)\n",
    "smooth = SmoothingFunction().method1\n",
    "b1=[sacrebleu.sentence_bleu(candidate, refs).score for candidate, refs in zip(m1, m2)]\n",
    "for i in range(len(m4)):\n",
    "    b2 = sentence_bleu(m4[i], m3[i], weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smooth)*100\n",
    "    b1.append(b2)\n",
    "print(sum(b1)/len(ds[1]['src']))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162c152",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9a092afd",
   "metadata": {},
   "source": [
    "## 9 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ad78c",
   "metadata": {},
   "source": [
    "from transformers import pipeline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145468b",
   "metadata": {},
   "source": [
    "pipe=pipeline('text2text-generation',model=merge_model,tokenizer=tokenizer,device=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d02ec1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pipe('机器翻译:\\n'+'我有一个苹果',max_length=30,do_sample=False)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
